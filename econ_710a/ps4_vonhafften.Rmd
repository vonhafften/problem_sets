---
title: "ECON 710A - Problem Set 4"
author: "Alex von Hafften^[I worked on this problem set with a study group of Michael Nattinger, Andrew Smith, and Ryan Mather. I also discussed problems with Sarah Bass, Emily Case, Danny Edgel, and Katherine Kwok.]"
date: "2/22/2021"
output: pdf_document
header-includes:
- \newcommand{\N}{\mathbb{N}}
- \newcommand{\Z}{\mathbb{Z}}
- \newcommand{\R}{\mathbb{R}}
- \newcommand{\Q}{\mathbb{Q}}
- \newcommand{\var}{\text{var}}
- \newcommand{\rank}{\text{rank}}
- \newcommand{\twiddle}{\tilde}
- \newcommand{\Lfn}{\mathcal{L}}
- \usepackage{bm}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
```

1. Let $X$ be generated by the following random coefficients discrete choice model $X= 1\{-U_0+ZU_1>0\}$ where $U= (U_0,U_1)'$ is independent of $Z$ and $Z\in\{0,1\}$. Provide conditions on $U$ such that $Pr(Defying) = 0$ and $Pr(Complying)>0$.

$Pr(Defying) = 0$ iff $X_U(1) = 0 \implies X_U(0) = 0$ and $X_U(0) = 1 \implies X_U(1) = 1$. $X_U(1) = 0 \implies X_U(0) = 0$ iff $-U_0+(1)U_1=-U_0+U_1<0 \implies -U_0 + (0)U_1 = -U_0< 0$. $X_U(0) = 1 \implies X_U(1) = 1$ iff $-U_0+(0)U_1=-U_0>0 \implies -U_0 + (1)U_1 = -U_0 + U_1 > 0$. Thus, $U_1 \ge 0$.

$Pr(Complying) > 0 \iff Pr(X_U(1) = 1$ and $X_U(0) = 0) > 0$. Since $U_1 \ge 0$, this implies that $U_1 > U_0 \ge 0$.

2. Let $\{Y_t\}^T_{t=1}$ be generated by the following MA(q) model, i.e., $Y_t=\mu+\varepsilon_t+\theta_1\varepsilon_{t-1}+...+\theta_q \varepsilon_{t-q}$ where $\{\varepsilon_t\}^T_{t=0}$ are i.i.d. random variables with mean zero and variance $\sigma^2$.

(i) Find the autocovariance function $\gamma(k)$.

For $k = 0$:

\begin{align*}
\gamma(0) 
&= Cov(Y_t, Y_t) \\
&= Var(Y_t) \\
&= Var(\mu+\varepsilon_t+\theta_1\varepsilon_{t-1}+...+\theta_q \varepsilon_{t-q})\\
&= Var(\varepsilon_t)+\theta_1^2 Var(\varepsilon_{t-1}+...+\theta_q^2 Var(\varepsilon_{t-q})\\
&= \sigma^2+\theta_1^2  \sigma^2+...+\theta_q^2 \sigma^2\\
&= \sigma^2(1 + \theta_1^2 +...+\theta_q^2)
\end{align*}

For $k = 1$:

\begin{align*}
\gamma(1) 
&= Cov(Y_t, Y_{t+1}) \\
&= Cov(\mu+\varepsilon_t+\theta_1\varepsilon_{t-1}+...+\theta_q \varepsilon_{t-q},
\mu+\varepsilon_{t+1}+\theta_1\varepsilon_{t+1-1}+...+\theta_q \varepsilon_{t+1-q})\\
&= Cov(\varepsilon_t+\theta_1\varepsilon_{t-1}+...+\theta_q \varepsilon_{t-q},
\varepsilon_{t+1}+\theta_1\varepsilon_{t}+...+\theta_q \varepsilon_{t+1-q})\\
&= Cov(\varepsilon_t+\theta_1\varepsilon_{t-1}+...+\theta_{q-1} \varepsilon_{t+1-q},
\theta_1\varepsilon_{t}+...+\theta_q \varepsilon_{t+1-q})\\
&= \theta_1Var(\varepsilon_t)+\theta_1\theta_2Var(\varepsilon_{t-1})+...+\theta_{q-1}\theta_qVar(\varepsilon_{t+1-q}) \\
&= \sigma^2(\theta_1+\theta_1\theta_2+...+\theta_{q-1}\theta_q)
\end{align*}

\pagebreak

For general $k$:

$$
\gamma(k) = 
\begin{cases} 
\sigma^2(1 + \theta_1^2 +...+\theta_q^2) 
&\text{ if }
k = 0 \\
\sigma^2 (\theta_k + \theta_1 \theta_{k+1} + \theta_2\theta_{k+1} + ... + \theta_{q-k}\theta_q)
&\text{ if }
0 < k \le q\\
0,
&\text{ if }
k > q
\end{cases}
$$

(ii) Suppose that $q= 1$ and find the autocorrelation function, $\rho(k) =\frac{\gamma(k)}{\gamma(0)}$. 

If $q=1$:

$$
Y_{t} = \mu+\varepsilon_t+\theta_1\varepsilon_{t-1}
$$

$\gamma(k)$ simplies to

$$
\gamma(k)
=
\begin{cases}
\sigma^2(1 + \theta_1^2 ),
&\text{ if }
k = 0 \\
\sigma^2\theta_1,
&\text{ if }
k = 1 \\
0,
&\text{ if }
k > 1
\end{cases}
$$

The autocorrelation function:

\begin{align*}
\rho(k) 
&= \frac{\gamma(k)}{\gamma(0)} \\
&=
\begin{cases}
\frac{\sigma^2(1 + \theta_1^2 )}{\sigma^2(1 + \theta_1^2 )},
&\text{ if }
k = 0 \\
\frac{\sigma^2\theta_1}{\sigma^2(1 + \theta_1^2 )},
&\text{ if }
k = 1 \\
\frac{0}{\sigma^2(1 + \theta_1 )},
&\text{ if }
k > 1
\end{cases} \\
&=
\begin{cases}
1,
&\text{ if }
k = 0 \\
\frac{\theta_1}{1 + \theta_1^2},
&\text{ if }
k = 1 \\
0,
&\text{ if }
k > 1
\end{cases}
\end{align*}

(iii) Is $\theta_1$ identified from the autocorrelation function?

No.  First, notice that $\theta_1$ only appears in autocorrelation function when $k = 1$.  If $\theta_1 = x$, $\theta_1 = 1/x$ yields the same value from the autocorrelation function:

\begin{align*}
\rho(1| \theta_1 = x) 
&= \frac{x}{1+x^2} \\
\rho(1| \theta_1 = x^{-1}) 
&= \frac{x^{-1}}{1+(x^{-1})^2}\\
&= \frac{x^{-1}}{1+x^{-2}}\frac{x^2}{x^2} \\
&= \frac{x}{1+x^2} 
\end{align*}

(iv) Suppose $\theta_1 \in [-1,1]$. Does you answer to (iii) change?

Yes, $\theta_1$ is identified by the autocorrelation function because if $\theta_1 = x \in [-1, 1] \implies 1/x \notin [-1, 1]$.

3. Consider an ARMA(1,1) model: $Y_t = \alpha_0 + Y_{t-1} \rho + U_t$ and $U_t = \varepsilon_t + \theta \varepsilon_{t-1}$ for all $t = 1, ..., T$; $Y_0 = \mu + \varepsilon_0 + \nu$ where $|\rho| < 1$, $|\theta | \le 1$, $\varepsilon_0, ..., \varepsilon_T$ are idd $N(0, \sigma^2)$ and independent of $\nu \sim N(0, \tau)$.

(i)  Find $\mu$ and $\tau$ (as functions of $\alpha_0, \rho, \theta$, and/or $\sigma^2$) such that $E[Y_t]$ and $Var(Y_t)$ does not depend on $t$.

...

(ii) For the $\mu$ and $\tau$ found above, you may use without proof that $\{Y_t\}^T_{t=1}$ is covariance stationary.  Under what conditions on $\alpha_0, \rho, \theta,$ and/or $\sigma^2$ is $(1,Y_{t-2})$ a valid instrument for $(1,Y_{t-1})$.

...

