ar(log(data$consumption), order.max = 1, method = "burg")
ar(log(data$consumption), order.max = 1, method = "ols")
library(Rtauchen)
ar(log(data$consumption), order.max = 1, method = "ols")
summary(lm(log(consumption) ~ lag(log(consumption)), data = data))
Rtauchen
?Rtauchen
Rtauchen(5, ssigma_eps = 0.01895, llambda_eps = 0.996738, m = .5)
Rtauchen(5, ssigma_eps = 0.01895, llambda_eps = 0.996738, m = .5)
options(scipen = 100)
Rtauchen(5, ssigma_eps = 0.01895, llambda_eps = 0.996738, m = .5)
Tgrid(5, ssigma_eps = 0.01895, llambda_eps = 0.996738, m = .5)
Rtauchen(5, ssigma_eps = 0.01895, llambda_eps = 0.996738, m = 2)
Tgrid(5, ssigma_eps = 0.01895, llambda_eps = 0.996738, m = 2)
exp(-0.4696093)
exp(0.4696093)
log(data$consumption)
histogram(log(data$consumption))
hist(log(data$consumption))
hist(diff(log(data$consumption)))
Rtauchen(5, ssigma_eps = 0.01895, llambda_eps = 0.996738, m = .5)
Tgrid(5, ssigma_eps = 0.01895, llambda_eps = 0.996738, m = .5)
histogram(log(data$consumption))
hist(log(data$consumption))
library(Rtauchen)
ar(log(data$consumption), order.max = 1, method = "ols")
summary(lm(log(consumption) ~ lag(log(consumption)), data = data))
hist(diff(log(data$consumption)))
Rtauchen(5, ssigma_eps = 0.01895, llambda_eps = 0.996738, m = .5)
Tgrid(5, ssigma_eps = 0.01895, llambda_eps = 0.996738, m = .5)
log(data$consumption)
lag(log(data$consumption))
log(data$consumption) - lag(log(data$consumption))
ar(log(data$consumption), order.max = 1, method = "ols")
summary(lm(log(consumption) ~ lag(log(consumption)), data = data))
library(Rtauchen)
ar(log(data$consumption), order.max = 1, method = "ols")
summary(lm(log(consumption) ~ lag(log(consumption)), data = data))
data %>%
mutate(shock = log(consumption) - lag(log(consumption))*0.996738 - 0.042301)
hist(diff(log(data$consumption)))
Rtauchen(5, ssigma_eps = 0.01895, llambda_eps = 0.996738, m = .5)
Tgrid(5, ssigma_eps = 0.01895, llambda_eps = 0.996738, m = .5)
library(Rtauchen)
ar(log(data$consumption), order.max = 1, method = "ols")
summary(lm(log(consumption) ~ lag(log(consumption)), data = data))
tauchen_data <- data %>%
mutate(shock = log(consumption) - lag(log(consumption))*0.996738 - 0.042301)
hist(tauchen_data$shock)
Rtauchen(5, ssigma_eps = 0.01895, llambda_eps = 0.996738, m = .5)
Tgrid(5, ssigma_eps = 0.01895, llambda_eps = 0.996738, m = .5)
Rtauchen
?Rtauchen
Rtauchen(5, ssigma_eps = 0.01895, llambda_eps = 0.996738, m = .4)
Tgrid(5, ssigma_eps = 0.01895, llambda_eps = 0.996738, m = .4)
hist(tauchen_data$shock)
library(Rtauchen)
ar(log(data$consumption), order.max = 1, method = "ols")
summary(lm(log(consumption) ~ lag(log(consumption)), data = data))
Rtauchen(5, ssigma_eps = 0.01895, llambda_eps = 0.996738, m = .4)
Tgrid(5, ssigma_eps = 0.01895, llambda_eps = 0.996738, m = .4)
tauchen_data <- data %>%
mutate(shock = (log(consumption) - lag(log(consumption))*0.996738 - 0.042301)/0.01895)
hist(tauchen_data$shock)
x_grid <- seq(-10, 10, by = 0.1)
lines(x = x_grid, x_grid)
pi
library(Rtauchen)
ar(log(data$consumption), order.max = 1, method = "ols")
summary(lm(log(consumption) ~ lag(log(consumption)), data = data))
Rtauchen(5, ssigma_eps = 0.01895, llambda_eps = 0.996738, m = .4)
Tgrid(5, ssigma_eps = 0.01895, llambda_eps = 0.996738, m = .4)
tauchen_data <- data %>%
mutate(shock = (log(consumption) - lag(log(consumption))*0.996738 - 0.042301)/0.01895)
hist(tauchen_data$shock)
x_grid <- seq(-10, 10, by = 0.1)
lines(x = x_grid, y = 1/sqrt(2*pi)*exp(-1/2 * x_grid^2))
1/sqrt(2*pi)*exp(-1/2 * x_grid^2)
library(Rtauchen)
ar(log(data$consumption), order.max = 1, method = "ols")
summary(lm(log(consumption) ~ lag(log(consumption)), data = data))
Rtauchen(5, ssigma_eps = 0.01895, llambda_eps = 0.996738, m = .4)
Tgrid(5, ssigma_eps = 0.01895, llambda_eps = 0.996738, m = .4)
tauchen_data <- data %>%
mutate(shock = (log(consumption) - lag(log(consumption))*0.996738 - 0.042301)/0.01895)
hist(tauchen_data$shock, freq = TRUE)
x_grid <- seq(-10, 10, by = 0.1)
lines(x = x_grid, y = 1/sqrt(2*pi)*exp(-1/2 * x_grid^2))
hist(tauchen_data$shock, freq = FALSE)
hist(tauchen_data$shock,probability = TRUE)
x_grid <- seq(-10, 10, by = 0.1)
lines(x = x_grid, y = 1/sqrt(2*pi)*exp(-1/2 * x_grid^2))
hist(tauchen_data$shock,probability = TRUE)
x_grid <- seq(-10, 10, by = 0.1)
lines(x = x_grid, y = 1/sqrt(2*pi)*exp(-1/2 * x_grid^2))
transition_m = Rtauchen(5, ssigma_eps = 0.01895, llambda_eps = 0.996738, m = .4)
transition_grid = Tgrid(5, ssigma_eps = 0.01895, llambda_eps = 0.996738, m = .4)
abline(v = transition_grid)
hist(tauchen_data$shock,probability = TRUE)
x_grid <- seq(-10, 10, by = 0.1)
lines(x = x_grid, y = 1/sqrt(2*pi)*exp(-1/2 * x_grid^2))
abline(v = transition_grid)
transition_m = Rtauchen(5, ssigma_eps = 1, llambda_eps = 0.996738, m = .4)
transition_grid = Tgrid(5, ssigma_eps = 1, llambda_eps = 0.996738, m = .4)
tauchen_data <- data %>%
mutate(shock = (log(consumption) - lag(log(consumption))*0.996738 - 0.042301)/0.01895)
hist(tauchen_data$shock,probability = TRUE)
x_grid <- seq(-10, 10, by = 0.1)
lines(x = x_grid, y = 1/sqrt(2*pi)*exp(-1/2 * x_grid^2))
hist(tauchen_data$shock,probability = TRUE)
x_grid <- seq(-10, 10, by = 0.1)
lines(x = x_grid, y = 1/sqrt(2*pi)*exp(-1/2 * x_grid^2))
abline(v = transition_grid)
transition_grid
transition_m = Rtauchen(5, ssigma_eps = 1, llambda_eps = 0.996738, m = .3)
transition_grid = Tgrid(5, ssigma_eps = 1, llambda_eps = 0.996738, m = .3)
hist(tauchen_data$shock,probability = TRUE)
x_grid <- seq(-10, 10, by = 0.1)
lines(x = x_grid, y = 1/sqrt(2*pi)*exp(-1/2 * x_grid^2))
abline(v = transition_grid)
transition_m = Rtauchen(5, ssigma_eps = 1, llambda_eps = 0.996738, m = .1)
transition_grid = Tgrid(5, ssigma_eps = 1, llambda_eps = 0.996738, m = .1)
hist(tauchen_data$shock,probability = TRUE)
x_grid <- seq(-10, 10, by = 0.1)
lines(x = x_grid, y = 1/sqrt(2*pi)*exp(-1/2 * x_grid^2))
abline(v = transition_grid)
transition_m = Rtauchen(5, ssigma_eps = 1, llambda_eps = 0.996738, m = .2)
transition_grid = Tgrid(5, ssigma_eps = 1, llambda_eps = 0.996738, m = .2)
tauchen_data <- data %>%
mutate(shock = (log(consumption) - lag(log(consumption))*0.996738 - 0.042301)/0.01895)
hist(tauchen_data$shock,probability = TRUE)
x_grid <- seq(-10, 10, by = 0.1)
lines(x = x_grid, y = 1/sqrt(2*pi)*exp(-1/2 * x_grid^2))
abline(v = transition_grid)
diff(transition_grid)
kernel(tauchen_data$shock,probability = TRUE)
kernel(tauchen_data$shock)
hist(tauchen_data$shock,probability = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(quantmod)
library(tis)
library(tidyverse)
library(knitr)
library(markovchain)
library(Rtauchen)
ar(log(data$consumption), order.max = 1, method = "ols")
getwd()
ar(log(data$consumption), order.max = 1, method = "mle")
knitr::opts_chunk$set(echo = TRUE)
library(quantmod)
library(tis)
library(tidyverse)
library(knitr)
library(markovchain)
knitr::opts_chunk$set(echo = TRUE)
library(quantmod)
library(tis)
library(tidyverse)
library(knitr)
library(markovchain)
# Solves for equilibrium pricing function
# states is n length vector
# q is n by n matrix of transition probabilities
solve_lucas <- function(states, q, beta, initial_guess) {
n <- length(states)
# Initial guess for pricing function
p <- rep(initial_guess, n)
# Setup iteration variables
tolerence <- 1e-8
iter <- 1
max_iter <- 10000
# Create history (for plotting)
history <- matrix(0, nrow = max_iter, ncol = n)
# Iterate until convergence or maximum iterations is reached
while(TRUE) {
# tp is the pricing function after the Bellman operator is applied.
tp <- rep(0, n)
# Apply Bellman operator for each current and for each future state
for (i in 1:n) {
for (j in 1:n) {
tp[i] <- tp[i] +
beta * (states[i] / states[j]) * (p[j] + states[j]) * q[i, j]
}
}
# Update history
history[iter, ] <- t(p)
# Break from loop if pricing function converged
if (max(abs(p - tp)) < tolerence) break
# Break from loop if maximum iteration is reached
if (iter >= max_iter) break
# update guess
p <- tp
iter <- iter + 1
}
# Trim history
history <- history[1:iter, ]
return(list(p=p, iter=iter, history=history))
}
ex1 <- solve_lucas(states = c(2, 1),
q = matrix(c(.8, .2, .2, .8),
nrow = 2, ncol = 2),
beta = 0.9,
initial_guess = 0)
print(ex1$p)
print(ex1$iter)
plot(1, type = "n",
xlim = c(0, ex1$iter),
ylim = c(min(ex1$history), max(ex1$history)),
xlab = "Number of Iterations",
ylab = "q(z)")
lines(ex1$history[,1])
lines(ex1$history[,2], lty =2)
points(y = ex1$history[1,], x= c(1, 1), pch = 8)
text(rep("Initial guess", 2), y = ex1$history[1,], x= c(1, 1), pos = 4)
knitr::opts_chunk$set(echo = TRUE)
library(quantmod)
library(tis)
library(tidyverse)
library(knitr)
library(markovchain)
# Solves for equilibrium pricing function
# states is n length vector
# q is n by n matrix of transition probabilities
solve_lucas <- function(states, q, beta, initial_guess) {
n <- length(states)
# Initial guess for pricing function
p <- rep(initial_guess, n)
# Setup iteration variables
tolerence <- 1e-8
iter <- 1
max_iter <- 10000
# Create history (for plotting)
history <- matrix(0, nrow = max_iter, ncol = n)
# Iterate until convergence or maximum iterations is reached
while(TRUE) {
# tp is the pricing function after the Bellman operator is applied.
tp <- rep(0, n)
# Apply Bellman operator for each current and for each future state
for (i in 1:n) {
for (j in 1:n) {
tp[i] <- tp[i] +
beta * (states[i] / states[j]) * (p[j] + states[j]) * q[i, j]
}
}
# Update history
history[iter, ] <- t(p)
# Break from loop if pricing function converged
if (max(abs(p - tp)) < tolerence) break
# Break from loop if maximum iteration is reached
if (iter >= max_iter) break
# update guess
p <- tp
iter <- iter + 1
}
# Trim history
history <- history[1:iter, ]
return(list(p=p, iter=iter, history=history))
}
ex1 <- solve_lucas(states = c(2, 1),
q = matrix(c(.8, .2, .2, .8),
nrow = 2, ncol = 2),
beta = 0.9,
initial_guess = 0)
print(ex1$p)
print(ex1$iter)
plot(1, type = "n",
xlim = c(0, ex1$iter),
ylim = c(min(ex1$history), max(ex1$history)),
xlab = "Number of Iterations",
ylab = "p(s)")
lines(ex1$history[,1])
lines(ex1$history[,2], lty =2)
points(y = ex1$history[1,], x= c(1, 1), pch = 8)
text(rep("Initial guess", 2), y = ex1$history[1,], x= c(1, 1), pos = 4)
print(ex1$p)
print(ex1$iter)
plot(1, type = "n",
xlim = c(0, ex1$iter),
ylim = c(min(ex1$history), max(ex1$history)),
xlab = "Number of Iterations",
ylab = "q(z)")
lines(ex1$history[,1])
lines(ex1$history[,2], lty =2)
points(y = ex1$history[1,], x= c(1, 1), pch = 8)
text(rep("Initial guess", 2), y = ex1$history[1,], x= c(1, 1), pos = 4)
solve_lucas([2.0, 1.0], [0.8 0.2; 0.2 0.8], 0.95, 0.0)
ex3 <- solve_lucas(states = c(2, 1),
q = matrix(c(.8, .2, .2, .8),
nrow = 2, ncol = 2),
beta = 0.95,
initial_guess = 0)
print(ex3$p)
print(ex3$iter)
plot(1, type = "n",
xlim = c(0, max(ex1$iter, ex3$iter)),
ylim = c(min(c(ex1$history, ex3$history)), max(c(ex1$history, ex3$history))),
xlab = "Number of Iterations",
ylab = "p(s)")
lines(ex1$history[,1], col = "blue")
lines(ex1$history[,2], col = "blue", lty = 2)
lines(ex3$history[,1], col = "red")
lines(ex3$history[,2], col = "red", lty = 2)
text("beta = .9", y = mean(ex2$history[ex2$iter, ]), x= ex2$iter/2, col = "blue")
load("data.RData")
ex4 <- solve_lucas(states = consumption_summary$consumption,
q = transition_matrix,
beta = .95,
initial_guess = 2000000)
consumption_summary <- data %>%
group_by(recession) %>%
summarise(consumption = round(mean(consumption)))
library(haven)
library(tidyverse)
setwd("/Users/alexandervonhafften/Documents/UW Madison/problem_sets/econ_810a/ps2/")
psid <- read_dta("../ps1/pequiv_long.dta")
View(psid)
names(psid)
names(psid$x11101LL)
psid$x11101LL
columns(psid)
colnames(psid)
label(psid)
labels(psid)
View(psid)
sample <- psid %>%
transmute(id = x11101LL,
year,
age = d11101,
cohort = year - age,
income = i11103,
is_seo = x11104LL == 12,
hours = e11101)%>%
filter(year >= 1978,
year <= 1997,
!is_seo,
age >= 25,
age <= 25 + 34,
income > 0)
hist(sample$hours)
50*40
hist(sample$hours)
hist(sample$hours, breaks = 30)
hist(sample$hours, breaks = 30)
50*37
50*37
hist(sample$hours, breaks = 60)
hline(50*37)
abline(h=50*37)
abline(v=50*37)
hist(sample$hours, breaks = 60)
abline(v=50*37)
abline(v=50*36)
abline(v=50*36, col ="red")
sample <- psid %>%
transmute(id = x11101LL,
year,
age = d11101,
cohort = year - age,
income = i11103,
is_seo = x11104LL == 12,
hours = e11101)%>%
filter(year >= 1978,
year <= 1997,
!is_seo,
age >= 25,
age <= 25 + 34,
income > 0,
hours > 50*36)
hist(sample$hours, breaks = 30)
abline(v=50*36, col ="red")
library(plm)
sample_panel <- pdata.frame(sample, index = c("id", "year"))
sample_panel$income_change <- (sample_panel$income - lag(sample_panel$income))/lag(sample_panel$income)
sample_panel$income_change
sample_panel$income_lag <- lag(sample_panel$income)
sample_panel$income_change <- (sample_panel$income - sample_panel$income_lag)/sample_panel$income_lag
mean(sample_panel$income_change, na.rm =TRUE)
hist(sample_panel$income_change)
winsor(sample_panel$income_change)
install.packages("sscore")
library(sscore)
sessionInfo()
mean(sample_panel$income_change, na.rm =TRUE, trim = 0.01)
max(sample_panel$income_change)
max(sample_panel$income_change, na.rm=TRUE)
hist(sample$income, log = TRUE)
sample
hist(log(sample$income))
hist(sample$income)
sample <- psid %>%
transmute(id = x11101LL,
year,
age = d11101,
cohort = year - age,
income = i11103,
is_seo = x11104LL == 12,
hours = e11101)%>%
filter(year >= 1978,
year <= 1997,
!is_seo,
age >= 25,
age <= 25 + 34,
income > 0,
income < exp(10),
hours > 50*36)
hist(sample$income)
sample <- psid %>%
transmute(id = x11101LL,
year,
age = d11101,
cohort = year - age,
income = i11103,
is_seo = x11104LL == 12,
hours = e11101)%>%
filter(year >= 1978,
year <= 1997,
!is_seo,
age >= 25,
age <= 25 + 34,
income > 0,
income < exp(11),
hours > 50*36)
hist(sample$income)
sample <- psid %>%
transmute(id = x11101LL,
year,
age = d11101,
cohort = year - age,
income = i11103,
is_seo = x11104LL == 12,
hours = e11101)%>%
filter(year >= 1978,
year <= 1997,
!is_seo,
age >= 25,
age <= 25 + 34,
income > 0,
income < exp(12),
hours > 50*36)
hist(sample$income)
sample <- psid %>%
transmute(id = x11101LL,
year,
age = d11101,
cohort = year - age,
income = i11103,
is_seo = x11104LL == 12,
hours = e11101)%>%
filter(year >= 1978,
year <= 1997,
!is_seo,
age >= 25,
age <= 25 + 34,
income > 0,
income < exp(13),
hours > 50*36)
hist(sample$income)
sample <- psid %>%
transmute(id = x11101LL,
year,
age = d11101,
cohort = year - age,
income = i11103,
is_seo = x11104LL == 12,
hours = e11101)%>%
filter(year >= 1978,
year <= 1997,
!is_seo,
age >= 25,
age <= 25 + 34,
income > 0,
income < exp(12),
hours > 50*36)
hist(sample$income)
sample_panel <- pdata.frame(sample, index = c("id", "year"))
sample_panel$income_lag <- lag(sample_panel$income)
sample_panel$income_change <- (sample_panel$income - sample_panel$income_lag)/sample_panel$income_lag
mean(sample_panel$income_change, na.rm =TRUE, trim = 0.01)
mean(sample_panel$income_change, na.rm =TRUE)
mean(sample_panel$income_change, na.rm =TRUE, trim = 0.01)
hist(sample_panel$income_change)
sample %>%
filter(income_change < 500)
sample_panel %>%
filter(income_change < 500)
sample_panel <- sample_panel %>%
filter(income_change < 500)
hist(sample_panel$income_change)
sample_panel <- sample_panel %>%
filter(income_change < 50)
hist(sample_panel$income_change)
sample_panel <- sample_panel %>%
filter(income_change < 10)
hist(sample_panel$income_change)
sample_panel <- sample_panel %>%
filter(income_change < 5)
hist(sample_panel$income_change)
sample_panel <- sample_panel %>%
filter(income_change < 3)
hist(sample_panel$income_change)
mean(sample_panel$income_change, na.rm =TRUE, trim = 0.01)
mean(sample_panel$income_change, na.rm =TRUE)
mean(sample_panel$income_change, na.rm =TRUE, trim = 0.01)
sample_panel <- sample_panel %>%
filter(income_change < 1)
hist(sample_panel$income_change)
mean(sample_panel$income_change, na.rm =TRUE, trim = 0.01)
# limits to income changes that are less than doubling.
sample_panel <- sample_panel %>%
filter(income_change < 1)
hist(sample_panel$income_change)
mean(sample_panel$income_change, na.rm =TRUE, trim = 0.01)
